{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S2.1$ Specifying Keys\n",
    "1. 一些转换操作(join, coGroup, keyBy, groupBy)需要以key为基础,而Dataset或DataStream中都是对象, 因此需要一种方式来指出使用对象中的哪个属性来作为key\n",
    "    * 使用Field Expressions: \n",
    "        * Dataset中是对象, 使用属性名选取. 比如有个对象的属性为user, 则直接填写\"user\"\n",
    "        * Dataset中是tuple, 使用1-offset或0-offset的index数. 比如_1和5表示tuple中第1个和第6个属性\n",
    "        * Dataset中是对象和tuple的嵌套类型, 则可任意嵌套选取, 比如\"user.\\_4.1.zip\"或\"\\_2.user.zip\"\n",
    "        * 可以使用通配符\"\\_\"选取Dataset中的整个对象作为key\n",
    "    * 使用Key Selector Functions\n",
    "        * 上面的字段表达式是一个字符串, 也可以直接传入一个函数提取出key\n",
    "    ```scala\n",
    "    // some ordinary case class\n",
    "    case class WC(word: String, count: Int)\n",
    "    val words: DataStream[WC] = // [...]\n",
    "    val keyed = words.keyBy( _.word )\n",
    "    ```\n",
    "    \n",
    "2. [transformation算子](https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/batch/)\n",
    "3. [接收partial function的算子](https://ci.apache.org/projects/flink/flink-docs-release-1.8/dev/scala_api_extensions.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\S2.2$ Iteration Operators\n",
    "* **Bulk Iterations**\n",
    "\n",
    "* **Delta Iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
