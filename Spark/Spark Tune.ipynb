{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一. submit参数调整, 使任务获取更多资源  \n",
    "```bash\n",
    "spark-submit \n",
    "--class  com.xingyun.test.WordCountCluster \n",
    "--num-executors    3            # 配置executor的数量 \n",
    "--driver-memory    2G         # 配置driver的内存（影响不大）\n",
    "--executor-memory   2G        # 配置每个executor的内存大小 \n",
    "--executor-cores   3            # 配置每个executor的cpu core数量 \n",
    "SparkTest-0.0.1-SNAPSHOT-jar-with-dependencies.jar  \n",
    "```\n",
    "\n",
    "1. case1：  \n",
    "把spark作业提交到Spark Standalone上面。一般自己知道自己的spark测试集群的机器情况。  \n",
    "举个例子：比如我们的测试集群的机器为每台4G内存，2个CPU core，5台机器。这里以可以申请到最大的资源为例，  \n",
    "那么  --num-executors  参数就设定为 5，  \n",
    "那么每个executor平均分配到的资源为：--executor-memory 参数设定为4G，--executor-cores 参数设定为 2 。\n",
    "\n",
    "2. case2：  \n",
    "把spark作业提交到Yarn集群上去。那就得去看看要提交的资源队列中大概还有多少资源可以背调度。举个例子：假如可调度的资源配置为：500G内存，100个CPU core，50台机器。 --num-executors  参数就设定为 50，那么每个executor平均分配到的资源为：--executor-memory 参数设定为 10G，--executor-cores 参数设定为 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二. \n",
    "https://www.jianshu.com/p/9555644ccc0f\n",
    "https://tech.meituan.com/spark_tuning_basic.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
