{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本部分介绍Executor的内存分配 \n",
    "\n",
    "#### 一. 堆外内存+堆内内存   \n",
    " Executor为了避免JVM的gc, 提供了对外内存, 直接向操作系统申请内存的方式. 这种方式需要手动申请释放内存  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二. 堆内内存\n",
    "1. 堆内内存四块    \n",
    " 堆内内存分为4部分: Execution内存,Storage内存,用户内存和预留内存  \n",
    "  1. Execution内存:   \n",
    "   供tasks公用的内存.用于存放shuffle,join,排序,聚合操作的中间结果  \n",
    "  2. Storage内存:  \n",
    "   用于存放cache的广播变量等  \n",
    "  3. 用户内存:  \n",
    "   存放RDD transformation所需的信息, 如RDD的依赖信息  \n",
    "  4. 预留内存:  \n",
    "   固定300M. 用于存放Spark的对象\n",
    "2. 内存分布图  \n",
    "如下图: 整个Executor的内存右`spark.executor.memory`参数配置  \n",
    "usableMemory = systemMemory - reservedMemory\n",
    "<img src=\"img/spark-onheap.png\" height=\"50%\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三. 堆外内存  \n",
    "1. 堆外内存只有Execution和Storage内存  \n",
    "2. 堆外内存默认关闭, 可以通过`spark.memory.offHeap.enabled`开启; 通过`spark.memory.offHeap.size`调整堆外内存大小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 四. Storage Memory 和 Execution Memory动态调整 \n",
    "1. 默认情况下, storage内存占整个Execuotr内存的60%,Execution内存占20%, 剩下的用于保留和执行程序的堆内存.   \n",
    "2. Spark 1.5 之前，Execution 内存和 Storage 内存分配是静态的: 如果 Execution 内存不足，即使 Storage 内存有很大空闲程序也是无法利用到的；反之亦然。这就导致我们很难进行内存的调优工作，我们必须非常清楚地了解 Execution 和 Storage 两块区域的内存分布。而目前 Execution 内存和 Storage 内存可以互相共享的。也就是说，如果 Execution 内存不足，而 Storage 内存有空闲，那么 Execution 可以从 Storage 中申请空间；反之亦然。所以上图中的虚线代表 Execution 内存和 Storage 内存是可以随着运作动态调整的，这样可以有效地利用内存资源。Execution 内存和 Storage 内存之间的动态调整可以概括如下：\n",
    "<img  src=\"img/storagememandexecmem.png\" height=\"80%\" width=\"80%\">\n",
    "\n",
    "具体的实现逻辑如下：\n",
    "* 程序提交的时候我们都会设定基本的 Execution 内存和 Storage 内存区域（通过 spark.memory.storageFraction 参数设置）；\n",
    "* 在程序运行时，如果双方的空间都不足时，则存储到硬盘；将内存中的块存储到磁盘的策略是按照 LRU 规则进行的。若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）\n",
    "* Execution 内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后\"归还\"借用的空间\n",
    "* Storage 内存的空间被对方占用后，目前的实现是无法让对方\"归还\"，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂；而且 Shuffle 过程产生的文件在后面一定会被使用到，而 Cache 在内存的数据不一定在后面使用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 五. task之间共享内存  \n",
    "1. 为了更好地使用使用内存，Executor内运行的Task之间共享着 Execution 内存。  \n",
    " 具体的，Spark内部维护了一个HashMap用于记录每个Task占用的内存。当Task需要在Execution内存区域申请numBytes内存，其先判断HashMap里面是否维护着这个Task的内存使用情况，如果没有，则将这个Task内存使用置为0，并且以TaskId为key，内存使用为value加入到HashMap里面。之后为这个Task 申请numBytes内存，如果Execution内存区域正好有大于numBytes的空闲内存，则在HashMap里面将当前Task使用的内存加上numBytes，然后返回；如果当前Execution内存区域无法申请到每个Task最小可申请的内存，则当前Task被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。每个 Task可以使用Execution内存大小范围为1/2N ~ 1/N，其中N为当前Executor内正在运行的Task个数。一个Task能够运行必须申请到最小内存为(1/2N * Execution 内存)；当N = 1的时候，Task可以使用全部的Execution内存。\n",
    "比如如果Execution内存大小为10GB，当前Executor内正在运行的Task个数为5，则该Task可以申请的内存范围为 10 / (2 * 5) ~ 10 / 5，也就是 1GB ~ 2GB的范围。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
